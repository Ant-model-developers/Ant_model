{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5662c489-5f85-4e69-b3df-b3fbfdefbc8b",
   "metadata": {},
   "source": [
    "# Supervised Finetuning\n",
    "The following notebook describes the supervised Finetuning-process.\n",
    "\n",
    "## Start Training\n",
    "To start the training, we have to restart the textgeneration-webui, using the following commands:\n",
    "    \n",
    "    conda activate textgen\n",
    "    cd /home/[...]/text-generation-webui/\n",
    "    python server.py --share --model models/Pre-ant-model --load-in-8bit\n",
    "\n",
    "Thereby, we load the Pre-ant-model (that is the new base model in the supervised finetuning-step) in 8bit.\n",
    "    \n",
    "After the webui started, the following steps have been executed within the webui:\n",
    "1. Switch to tab \"Training\"\n",
    "2. Give the LoRA-file a new name - in our case \"Pre_ant_adapter\"\n",
    "3. Adapt the Hyperparameters for the training:\n",
    "    -\tTraining-epochs: 20\n",
    "    -\tLearning-rate: 3e^-4\n",
    "    -\tLoRA Rank: 8\n",
    "    -\tLoRA Alpha: 16\n",
    "    -\tBatch Size: 128\n",
    "    -\tMicro Batch Size: 4\n",
    "    -\tCutoff Length: 256\n",
    "    -\tLR Scheduler: linear\n",
    "4. Go to the Tab \"Formatted Dataset\"\n",
    "5. Adapt the Dataselection:\n",
    "    - Data-Format: alpaca-format\n",
    "    - Dataset: Structured_training_dataset\n",
    "    - Evaluation Dataset: None\n",
    "6. Click \"Start LoRA Training\"\n",
    "\n",
    "After 3 hours the new LoRA-adapter was saved to the folder \"text-generation-webui/loras/Ant_adapter\".\n",
    "\n",
    "### Create Ant-model\n",
    "The new Ant-model is created by merging the newly trained LORA-adapter (Ant-adapter) with the corresponding base model (Pre-ant-model). Afterwards, it is pushed to the huggingace hub \"Ant_model_developers/Ant_model\"  Therefore, we executed the following code from this notebook:\n",
    "\n",
    "#### Load Base-model, tokenizer, LoRA-adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011190a1-5107-49c3-a01a-75925a713f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install huggingface_hub\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a0465-ea5b-4846-ae8b-5abfd670cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79e3d7-8f70-43d2-8536-7a164c412971",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"text-generation-webui/models/Pre-ant-model/\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1bd215-04c5-4413-bdce-638f833e0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295e703-6cb9-4a3d-8eb1-f7cc6245d341",
   "metadata": {},
   "source": [
    "#### Combine base model with LoRA-adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b1938-9a52-412e-8a41-5df57e9ad85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = PeftModel.from_pretrained(model, 'text-generation-webui/loras/Ant-adapter/', is_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364515c7-a609-4c15-8130-061de993b9aa",
   "metadata": {},
   "source": [
    "#### Merge base model with LoRA-adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f0f8a3-8538-483d-b7f1-5e75f8c28443",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = peft_model.merge_and_unload()\n",
    "merged_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a069f4-08ce-4d74-a00c-02a2870edbe4",
   "metadata": {},
   "source": [
    "#### Save merged model to text-generation-webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913bf953-b053-40b6-8f45-3a831d62093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model.save_pretrained(\"text-generation-webui/models/Ant-model/\", safe_serializetion=True)\n",
    "tokenizer.save_pretrained(\"text-generation-webui/models/Ant-model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972b85c-92cf-4b3b-8eea-08090ca4f5d9",
   "metadata": {},
   "source": [
    "#### Push model to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b184e-dbb9-492b-8ecb-5ac3f60c8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"XXXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53aedb5-e0cc-4d0d-b621-fb5317144aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import push_to_hub\n",
    "merged_model.push_to_hub(\"Ant-model-developers/Ant_model\")\n",
    "tokenizer.push_to_hub(\"Ant-model-developers/Ant_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - Cuda (ipykernel)",
   "language": "python",
   "name": "python3-jr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
